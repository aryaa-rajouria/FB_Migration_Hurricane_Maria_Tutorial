---
title: "The Impact of Hurricane Maria on Out-Migration From Puerto Rico"
author: "Aryaa Rajouria, Crystal Yu"
date: "May 31 2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)

```

```{r}
knitr::include_url("https://rstudio.com")
```

```{r}
knitr::include_app("https://yihui.shinyapps.io/miniUI/")
```
##Introduction 

Today, we will be going through [The Impact of Hurricane Maria on Out-migration from Puerto Rico: Evidence from Facebook Data](https://www.jstor.org/stable/pdf/45216967.pdf). The GitHub Repository can be found [here](https://canvas.uw.edu/courses/1549181/modules/items/15393060).

In this paper, Alexander et al use Facebook advertising data to estimate migration of Puerto Ricans to the continental United States after Hurricane Maria. Given the large scale use of Facebook in Puerto Rico, they argue that using Facebook data is appropriate in this instance. They collect Facebook demographic data every 2-3 months (they have six waves in total) from January 2017 to March 2018. Hurricane Maria took place between September 2017 and October 2017, enabling the authors to see the effect of the hurricane on the population demographics. They use a difference-in-difference model to compare the size of the population before and after the hurricane, finding that between October 2017 and January 2018, there was a 17% increase in the number of migrants from Puerto Rico the the continental United States--with the most migrating to Florida. They also find that there were more male migrants than females, and there were more in younger working age groups. They also find that after the hurricane, 1.8% of migrants returned to Puerto Rico. The findings aligned with prior research. 

A few examples of instances in which the Facebook Ads Manager has previously been used include: 
  *[Tracking cross-border migration in Europe during the Coronavirus pandemic](https://globalizationandhealth.biomedcentral.com/articles/10.1186/s12992-022-00832-6)
  *[Using FacebookAds for election polling](https://dl.acm.org/doi/abs/10.1145/3323503.3349552)
  *[To create estimates to improve global development statistics](https://www.itu.int/dms_pub/itu-s/opb/journal/S-JOURNAL-ICTF.VOL1-2018-2-P04-PDF-E.pdf)

In this R Tutorial, we will be using the data Alexander et al. provide on GitHub for replicability. We will not be extracting new data from the Facebook API. However, this is the general process: 

1. Access the Web Interface of the Marketing API [here](https://www.facebook.com/adsmanager/manage/campaigns?act=147920879) and define attributes.
2. If you're using R, install the pySocialWatcher which can be found [here](https://github.com/maraujo/pySocialWatcher).
2. Create a developer account and obtain an [access token](developers.facebook.com/tools/accesstoken) as a Facebook developer.
3. Access Facebook data that is publicly [available](https://developers.facebook.com/docs/graph-api if want to collect data on anything that is available publicly)

For more information on how to extract data from the Facebook Ads Manager API using R see [here](https://worldbank.github.io/connectivity_mapping/facebook_nbs/pipeline.html).

You may find more information on how to extract FB data using the API & Python: [here](https://developers.facebook.com/docs/graph-api/overview/), [here](https://developers.facebook.com/blog/post/2017/04/18/graph-api-v2.9/), and [here](https://towardsdatascience.com/how-to-use-facebook-graph-api-and-extract-data-using-python-1839e19d6999). 


##Load in Necessary Libraries 

First, we will download the necessary libraries. Please note that if you have downloaded the authors' repo from GitHub, you will need to download narcan (also from GitHub) to convert FIPS codes. 
```{r}
## load libaries
library(kableExtra)      # for making pretty tables
library(RColorBrewer)    # for color palettes
library(lubridate)       # for time data
library(rnaturalearth)   # for world shapefile
library(sf)              # simple feature mapping
library(mapview)         # for simple interactive mapping
library(tmap)            # for interactive mapping
library(tidyverse)       # for data wrangling  
library(ggplot2)         # for pretty graphs
#library(narcan)
```


##Loading in the Facebook Data

```{r, results='hide'}
## load the raw facebook data
#fb.raw <- read_csv("./data/facebook/master_acs_facebook_data.csv")  # if you've downloaded or cloned the github repo, otherwise
fb.raw <- read_csv("https://raw.githubusercontent.com/MJAlexander/fb-migration-hurricane-maria/master/data/facebook/master_acs_facebook_data.csv") 

dim(fb.raw)  # 25,200 rows, 30 columns

## clean the data
fb <- fb.raw %>%
  # extract age group from character string (ex ages_15_19)
  mutate(age_group = as.numeric(unlist(lapply(strsplit(age_group, "_"), '[[', 2)) ) ) %>% 
  #select relevant variables 
  select(state, origin, age_group, sex, expat_population_wave1:facebook_population_wave7) %>%
  # add wave indicator
  pivot_longer(5:18, names_to="var", values_to="value") %>% 
  mutate(wave = as.numeric(substr(var, str_length(var), str_length(var)) ),
         var = substr(var, 1, str_length(var)-6)) %>%
  pivot_wider(names_from=var, values_from=value) %>%
  # "fix" state names (states with a space in the name, e.g. new york, are coded with an underscore in the name, e.g. new_york)
  mutate(state = ifelse(grepl("_", state), str_replace(state, "_", " "), state))
  
## add in corresponding dates for each wave: 
##this requires lubridate package (part of the tidyverse, for date/time data, but need to separately load library)
fb <- fb %>% 
  mutate(date = case_when(
    wave==1~ymd(20170101),
    wave==2~ymd(20170401),
    wave==3~ymd(20170601),
    wave==4~ymd(20171001),
    wave==5~ymd(20180101),
    wave==6~ymd(20180301),
    wave==7~ymd(20180701)
  ))

```
Note: The data from waves 6 and 7 have many "1000"s in the `expat_population` column, this could be suggestive of rounding/bottom-coding. However, this may hide other potential issues. Unclear if/to what extent this is also present with data from the earlier waves, and whether other data issues may be present. In general there is definitely some rounding here since the numbers are "too" neat.

```{r}
# look at unique expat groups: where they're going-- interesting, even though we're only looking at PR for this study 
unique(fb$origin) 
```
```{r}
## look at cleaned fb data
#dim(fb)  # 176,400 rows, 8 columns: 7 waves x 2 sex x 9 age groups x 50 states x 28 origin countries
glimpse(fb)   # note the date format on the date column
```

## Descriptives
(summary and/or introduction)

[numbers here look the same: talk to Crystal]
```{r}
sex_tab <- table(fb$sex)
prop.table(sex_tab)

state_tab <- table(fb$state)
state_tab
```


### National FB population estimates
```{r}
## estimate total facebook population by wave
# filtering by Mexico but it doesn't matter - all countries are the same total population

# this is supposed to be the total (fb) population per state-age-sex-wave combination
total_fb_pop <- fb %>% filter(origin=="Mexico") %>% group_by(wave) %>% summarise(fb = sum(facebook_population))

kable(total_fb_pop, 
      format.args=list(big.mark=','), col=c("wave", "estimated US pop")) %>%
  kable_paper()

```


```{r, include=FALSE, echo=FALSE}
# alternatively
#fb %>%
#  # remove duplicate entries
#  distinct(state, age_group, sex, wave, facebook_population, date) %>%
#  # calculate estimated population by wave
#  group_by(wave) %>%
#  summarize(facebook_population = sum(facebook_population), .groups='drop')
```



### National FB expat populations
```{r}
## unique expat groups (country of origin)
(fb.origins <- unique(fb$origin))  # there are only 28, as noted in the paper


## size of expat groups in the us, according to the fb data
fb.expat <- fb %>% #filter(wave <= 5) %>%  # the counts for waves 6 and 7 look really off when compared to wave 5
  group_by(origin, wave) %>% 
  summarise(expat_pop = sum(expat_population), .groups='drop') %>% 
  arrange(wave, -expat_pop) %>%
  mutate(wave = paste0("pop_wave", wave)) %>%
  pivot_wider(names_from=wave, values_from=expat_pop) 

fb.expat %>%
  kable(format.args=list(big.mark=',')) %>%
  kable_paper("hover")

```

[the differences in counts between waves 5, 6 illustrate that fb data can suddenly change - unsure if algorithm or privacy revisions in this instance. the cambridge analytica fb data scandal occurred around this time. the media coverage may have spurred fb to quickly change how they produce their estimates, and how data is displayed (e.g. bottom-coding, rounding).]


### WA FB total population + expat population
(estimates fluctuate by wave. notice large jump in estimated expat pop size between waves 5 and 6, 6 and 7. suggests data may not be most reliable. but also illustrates a significant barrier in using fb data for research.)

```{r}
## estimated wa population by wave, according to fb
wa.fb <- fb %>%
  filter(state == "Washington") %>%
  # remove duplicate entries
  distinct(state, age_group, sex, wave, facebook_population, date) %>%
  group_by(wave) %>%
  summarize(facebook_population = sum(facebook_population), .groups='drop')

## estimated expat population in wa, according to fb
  # notice there's a big jump in numbers between waves 5 and 6
fb %>% 
  filter(state == "Washington") %>%
  group_by(wave) %>%
  summarize(expat_pop = sum(expat_population)) %>%
  # merge in fb population
  left_join(wa.fb, by="wave") %>%
  mutate(expat.prop = round(expat_pop/facebook_population, 3)) %>%
  kable(format.args=list(big.mark=','),
        col=c("wave", "estimated WA expat pop", "estimated WA total pop", "proportion WA expat")) %>% kable_paper("hover")
  

## estimated expat population in wa by country of origin (waves 1-5 only)
fb %>%
  filter(state == "Washington" & wave <= 5) %>%  # looks ok(?) for can, cn, in, mx, ph, vn in waves 6, 7. there's a sizable increase in numbers between waves 5 and 6
  # calculate number of expats by country of origin, by wave
  group_by(wave, date, origin) %>%
  summarize(expat_pop = sum(expat_population), .groups='drop') %>%
  mutate(wave = paste0("wave", wave)) %>%
  pivot_wider(names_from=c(wave, date), values_from=expat_pop) %>%
  kable(format.args=list(big.mark=','), caption = "estimated number of migrants in WA by country of origin") %>%
  kable_paper("hover")


```


## Maps
### Static map
(summary or intro to maps)

```{r}
## plot the data on expat groups
# this is from ggplot2
world_map <- map_data("world")  
#head(world_map)  # this is lat/long point data

## map of fb data for october 2017
fb.pop.counts.w4 <- fb %>% 
  filter(wave == 4) %>%  
  group_by(origin, wave) %>%
  summarize(pop = sum(expat_population), .groups='drop') %>%
  arrange(pop) 

fb.pop.counts.w4 %>%
  # need to keep all country outline data
  right_join(world_map,
            by=c("origin"="region") ) %>%
  # note that mexico has a large number while other countries are much smaller in comparison
  # might need to log scale, or set manual breaks for comparison
  ggplot() +
  geom_polygon(aes(x=long, y=lat, group=group, fill=log(pop)), color="black") +
  coord_fixed(1.3) +
  scale_fill_distiller(na.value="white", direction=1, palette="Reds", name="estimated expats \n in log(population)") +
  labs(subtitle="Country of origin of US migrants, estimated from FB data (Oct 2017)") +
  theme_void() +
  theme(legend.position="bottom")

```

### Interactive maps
#### mapview
More info here: [mapview tutorial](https://bookdown.org/nicohahn/making_maps_with_r5/docs/mapview.html)


[documentation](https://cran-r-project.org/web/packages/mapview/mapview.pdf)

not much customization was done here. this is a quick way to create a simple interactive map for exploratory data analysis, including spatial context

```{r}
## download world outline data (sf)
#require(rnaturalearth)
world <- ne_countries(scale="medium", returnclass="sf")

## create interactive map displaying fb estimates by country of origin
world %>% 
  sf::st_transform(crs=4326) %>%  
  # merge in fb population estimates to shapefile
  left_join(fb.pop.counts.w4, by=c("admin"="origin")) %>%
  select(admin, name, pop_est, continent, region_un, subregion, geometry, wave, pop) %>%
  mapview(zcol="pop",  # which column to map
          map.types=c("OpenStreetMap", "CartoDB.Positron", "Esri.WorldImagery"),  # define which base map(s) to display
          at=c(0, 5e4, 1e5, 2e5, 5e5, 1e6, 2e6, max(fb.pop.counts.w4$pop) ),  # manually define categorical breaks
          col.regions=brewer.pal(7, "YlGn")   # specify color palette              
          )

```

#### tmap
```{r}
#require(tmap)
tmap_mode("view")   # interactive mode
#tmap_mode("plot")  # static map (this is the default)

## create interactive map displaying fb estimates by country of origin
world %>% 
  left_join(fb.pop.counts.w4, by=c("admin"="origin")) %>% 
  tm_shape() +
  tm_fill(col="pop", # which column to plot
          id="name", # what to display
          breaks=c(0, 5e4, 1e5, 2e5, 5e5, 1e6, 2e6, max(fb.pop.counts.w4$pop)),  # manually define breaks
          palette="YlGn") + # specify color palette
  tm_borders()  # add in borders

```

---

# American Community Survey (ACS) data

```{r include=F, echo=F}
# (there's a bunch of code for cleaning the IPUMS data, though the IPUMS raw file is not included on the github repo. Currently attempting to recreate the `acs_prop_age` file from downloading the specified data from IPUMS but am getting a different number of records.)

```

Code on github repo indicates IPUMS download of the 2017 1-year ACS data with sex, age, bpl, (statefip) variables

```{r}
# read in pre-saved ACS 2017 1-year data
#acs_prop_age <- read_csv("./data/acs_prop_age.csv")  # if cloned/downloaded the github repo, otherwise
acs_prop_age <- read_csv("https://raw.githubusercontent.com/MJAlexander/fb-migration-hurricane-maria/master/data/acs_prop_age.csv")

```

## Descriptives of ACS data
(comparing the fb estimates and acs estimates, to assess bias)

### National level differences
```{r}
## national level estimates of number of "expats" in the acs, compared to fb estimates
acs.fb.comp <- acs_prop_age %>%
  # calculate number of estimated migrants by country of birth  
  group_by(origin, bpl) %>%
  summarize(acs.est = sum(no_mig), .groups='drop') %>%
  select(-bpl) %>%
  # keep only the countries available in the fb data
  filter(origin %in% fb.origins) %>%
  # merge in fb expat data estimates
  right_join(fb.expat %>% select(1:5) %>%  # waves 1-4 "technically" more comparable since covers 2017
               rowwise() %>% mutate(fb.avg = mean(c_across(cols=2:5))) %>% ungroup() , # compute mean estimate over the 4 waves
             by="origin") %>%
  # compute difference between acs and fb estimates
  mutate(diff = acs.est - fb.avg) %>%
  arrange(diff) %>%
  relocate(fb.avg, .after=acs.est) %>%
  relocate(diff, .after=fb.avg)

kable(acs.fb.comp %>% select(1:4), format.args=list(big.mark=',')) %>%
  kable_paper("hover")

```


```{r, include=F, echo=F}
## map the results, to see if potential regional differences
#world %>% left_join(acs.fb.comp, by=c("admin"="origin")) %>%
#  select(admin, name, pop_est, continent, region_un, subregion, geometry, acs.est, fb.avg, diff) %>%
#  mapview::mapview(zcol="diff",  # which column to map
#                   map.types=c("OpenStreetMap", "CartoDB.Positron", "Esri.WorldImagery"),  # define which base map(s) to display
#                   at=c(min(acs.fb.comp$diff), -1e4, 0, 1e5, 5e5, 1e6, max(acs.fb.comp$diff))  # manually define categorical breaks
#                   )

```

(note: positive values = larger ACS estimate; negative values = larger fb values. \\
might be interesting to ponder as to why we might see such different acs/fb estimates - self-reports?\\
to check: if there are distinctive regional patterns.)

[tangent: the large fb underestimate of individuals from china makes sense, given the great firewall and fb being banned there]


### State level differences
(looking only at states with PR pop 18000+ only)\\
The authors excluded North Carolina due to some unexplained data anomaly (eyeballing it, can't tell where or what the anomaly might be - especially since the acs number looks comparable?). They also examined only states with 18,000+ PRs to avoid rounding(?) issues

```{r}
# 4. Top states based on PR population --------------------------------

# table of expat populations and proportions in facebook and acs
# remove North Carolina because there seems to be an anomaly in the data 
# filter to include only states above 18000 to avoid rounding issues. 

pr.state <- fb %>% 
  filter(!state %in% c("North Carolina")) %>% 
  # keep fb wave 4 data only, and origin country = pr
  filter(wave==4, origin=="Puerto Rico") %>% 
  # merge in acs data on pr population
  left_join(acs_prop_age %>% 
              filter(origin == "Puerto Rico"),
            by=c("state", "origin", "age_group", "sex")) %>%   
  # calculate for each state:
  group_by(state) %>% 
  summarise(expat_population = sum(expat_population),  #  total fb pr expat population
            total_pop = sum(facebook_population),   # total fb population 
            expat_population_acs = sum(no_mig),  # total acs pr migrant pop
            expat_proportion_acs = round(sum(prop_pop), 3)  # proportion of migrants in state
            ) %>% 
  # calculate fb expat proportion (out of all fb users)
  mutate(expat_proportion = round(expat_population/total_pop, 3)) %>% 
  select(state, expat_population, expat_population_acs, expat_proportion, expat_proportion_acs) %>% 
  # arrange in decreasing numbers of fb pr migrants by state
  arrange(-expat_population) 

# states where pr expat pop > 18000 (12, if north carolina not dropped)
pr.state %>% 
  filter(expat_population>18000) %>%
  kable(format.args=list(big.mark=',')) %>%
  kable_paper("hover")

```

(I thought about making comparison maps by data source, but since the pr population is pretty small in most states the maps might not be very informative)


# Comparing FB and ACS data
(summary)

## Age distribution
```{r}
# 7. age change -----------------------------------------------------------

## compare age distributions (figure 1 in the paper)
acs_prop_age %>% 
  # pr individuals in the acs only
  filter(origin=="Puerto Rico") %>% 
  # merge in fb data on pr expats from wave 1 (jan 2017)
  left_join(fb %>% filter(wave==1, origin=="Puerto Rico")) %>% 
  # calculate proportion of expats in each age group out of total fb pop per sex-state combination
  group_by(state, sex) %>% 
  mutate(expat_prop = expat_population/sum(expat_population, na.rm = T)) %>% 
  ungroup() %>%
  select(state, sex, age_group, prop_mig, expat_prop) %>% 
  # look at 9 selected states, males
  filter(sex==1, state %in% c("Florida", "New York", "New Jersey", 
                              "Pennsylvania", "Connecticut", "Illinois",
                              "California", "Texas", "Massachusetts")) %>% 
  ggplot(aes(age_group, prop_mig)) + 
  geom_line(lwd = 0.8) + 
  geom_line(aes(age_group, expat_prop), color = "red", lty = 2, lwd = 0.8) + 
  facet_wrap(~state)+
  theme_bw(base_size = 14) + 
  ylab("proportion") + xlab("age group")

```

## Sex ratio
(for states with larger pr populations, in general fb data indicates higher m:f sex ratio. however, not true in tx and ca)
```{r}
# 8. sex change -----------------------------------------------------------

#https://stats.stackexchange.com/questions/21167/standard-error-of-a-ratio

# sex ratios in ACS vs fb, by state  (table 1 in the paper)
sr.nat <- acs_prop_age %>% 
  mutate(pr = ifelse(origin== "Puerto Rico", 1, 0)) %>% 
  group_by(state, pr, sex) %>%
  summarise( no_mig = sum( no_mig, na.rm = T)) %>% 
  group_by(state, pr) %>% 
  # acs sex ratio
  summarise(sr_acs = no_mig[sex==1]/no_mig[sex==2]) %>% 
  group_by(state) %>% 
  filter(state %in% c("Florida", "New York", "New Jersey", 
                      "Pennsylvania", "Illinois", "California", "Connecticut",
                      "Texas", "Massachusetts")) %>% 
  left_join(fb %>% 
              mutate(pr = ifelse(origin== "Puerto Rico", 1, 0)) %>% 
              mutate(expat_population = ifelse(state=="Connecticut"&age_group==35&wave==4&sex==1&pr==1, 4300, expat_population)) %>% 
              group_by(wave, state, pr, sex) %>%
              summarise(expat_population = sum(expat_population, na.rm = T)) %>% 
              group_by(wave, state, pr) %>% 
              summarise(sr_fb = expat_population[sex==1]/expat_population[sex==2]) %>%  # fb sex ratio (m:f)
              filter(state %in% c("Florida", "New York", "New Jersey", 
                                  "Pennsylvania", "Illinois", "California", "Connecticut",
                                  "Texas", "Massachusetts"), wave<6)) %>%  ungroup() %>%
  filter(pr==1, wave==1) %>% select(-pr, -wave)

## plot difference in sex ratio by data source, for select states
sr.nat %>%
  pivot_longer(2:3, names_to="source", values_to="sr") %>%
  separate(source, into=c(NA, "source")) %>%
  ggplot(aes(y=state, x=sr, color=source)) +
  geom_point() +
  geom_vline(xintercept=1, linetype=2) +
  labs(x="sex ratio") +
  theme_bw() +
  theme(legend.position="bottom")

```

---

# Difference-in-Differences Estimation
(summary of diff-in-diff)

[wikipedia](https://en.wikipedia.org/wiki/Difference_in_differences)

In this paper, the diff-in-diff estimator is
$$
\pi_{g} = \frac{P_{g}^{PR}(5) - P_{g}^{PR}(4)}{P_{g}^{PR}(4)} - \frac{P_{g}^{c}(5) - P_{g}^{c}(4)}{P_{g}^{c}(4)} 
$$
where $g$ is the group of interest (age, sex, country of origin, state of residence).

(Control group: expats from all other countries aside from Mexico, which is assumed to follow different migration motivations, dynamics(?))

Effectively, comparing the change in PR migrant population in the US between waves with the change in population for all other migrants (but not Mexican immigrants).


## National diff-in-diff estimate
```{r}
exp_prop_usa <- fb %>% 
  # exclude migrants from puerto rico or mexico
  filter(origin != "Puerto Rico", origin != "Mexico") %>%
  # calculate number of expats in each wave
  group_by(wave) %>% 
  summarise(expat = sum(expat_population)) %>% 
  # add in total number of fb users per wave
  left_join(total_fb_pop, by="wave") %>% 
  # calculate proportion of expats out of total fb population
  mutate(prop = expat/fb) %>% 
  # merge this information back into fb data
  left_join(fb %>% 
              # calculate number of pr expats in the us, per wave
              filter(origin=="Puerto Rico") %>% 
              group_by(wave) %>% 
              summarise(expat_pr = sum(expat_population)),
            by="wave") %>% 
  # calculate proportions
  mutate(prop_pr = expat_pr/fb,  # proportion of pr expat users among total fb users
         var_prop = prop*(1-prop)/(fb/1000),  # binomial variance for all other migrants (excludes mx) 
         var_prop_pr = prop_pr*(1-prop_pr)/(fb/1000)) %>%  # binomial variance for pr migrants
  # calculate diff in diff  
  mutate(prop_diff = (prop - lag(prop))/lag(prop),  # calculate difference in proportion of all other migrants between waves
         se_diff = sqrt(var_prop + lag(var_prop)),  
         prop_pr_diff = (prop_pr - lag(prop_pr))/lag(prop_pr),  # calculate difference in pr migrants
         se_diff_pr = sqrt(var_prop_pr + lag(var_prop_pr)),  
         diff_in_diff = (prop_pr_diff - prop_diff)*100,  # calculate diff-in-diff estimator, x100 to get pct
         se_diff_diff = sqrt(se_diff^2 + se_diff_pr^2)*100)  # calculate se for diff-in-diff estimator

# pull out diff-in-diff estimator (+se) between waves 4 and 5
res <- exp_prop_usa %>% filter(wave==5) %>% 
  select(percent_increase = diff_in_diff, se = se_diff_diff) %>% 
  # calculate ~95% ci
  mutate(ci_lower = percent_increase - 2*se, 
         ci_upper = percent_increase + 2*se)

res 

```

### National estimate of PR in-migrants
Use estimated percent with ACS population data to obtain estimate of PR migrants in the US 

$$\hat{M}_{g} = \hat{\pi}_{g} \times P_{g}^{ACS}$$
where $\hat{M_{g}}$ is the estimated number of migrants in group $g$, $\hat{\pi}_{g}$ is the proportional change in PR migrants in group $g$, and $P_{g}^{ACS}$ is the estimated number of PR migrants in group $g$ in the ACS

```{r}
acs_prop_age %>% 
  filter(origin=="Puerto Rico") %>% 
  # calculate mean number of migrants, using previously calculated percentage of movers and 95% bounds
  summarise(mean = sum(no_mig)*res$percent_increase/100, 
            lower = sum(no_mig)*res$ci_lower/100, 
            upper = sum(no_mig)*res$ci_upper/100)

```



## State diff-in-diff estimators
(`expat_pop` = 20 seems to be some form of filler data - it gets excluded from the data, but reasoning is not explained.
Also, North Carolina is to be excluded - not quite sure why )

```{r}
# 5a. State by state analysis (table) ----------------------------------------------

## calculate approximate population per state, by state and wave, using fb data
total_fb_pop_state <- fb %>% filter(origin=="Mexico") %>% 
  group_by(wave, state) %>% 
  summarise(fb = sum(facebook_population), .groups='drop')

## calculate expat population proportions by waves
ex_props <- fb %>%
  filter(!state %in% c("North Carolina")) %>%  # exclude north carolina (?)
  # exclude all expats from puerto rico, mexico, where expat_pop = 20 (?)
  filter(origin!="Puerto Rico", origin!= "Mexico", expat_population>20) %>%
  # calculate for each state and fb wave, total number of expats from all origins besides mx, pr
  group_by(state, wave) %>%
  summarise(expat = sum(expat_population), .groups='drop') %>%
  # merge back fb population by state
  left_join(total_fb_pop_state,
            by=c("state", "wave")) %>% 
  # calculate proportion of fb expats in each state
  mutate(prop = expat/fb) %>% 
  group_by(state) %>%
  # merge in data on pr migrants from the fb data
  left_join(fb %>%
              filter(origin=="Puerto Rico") %>%
              # calculate number of pr expats in each state, by wave
              group_by(state, wave) %>%
              summarise(expat_pr = sum(expat_population), .groups='drop'),
            by=c("state", "wave") ) %>% 
  # calculate for each state
  mutate(prop_pr = expat_pr / fb,  # proportion of pr expats out of total fb users
         var_prop = prop*(1-prop)/(fb/1000),  # variance for proportion of expats out of total fb users 
         var_prop_pr = prop_pr*(1-prop_pr)/(fb/1000)) %>%  # variance for proportion of pr users out of total fb users
  # calculate diff in diff estimator for each state
  # this will throw some warning messages for several states (ak, nd, sd, vt, wy)
  # (from the huge difference in expat_pop between waves 5 and 6, 6 and 7)
  group_by(state) %>%
  mutate(prop_diff = (prop - lag(prop))/lag(prop),  # difference in proportion of expats between waves
         se_diff = sqrt(var_prop + lag(var_prop)),  
         prop_pr_diff = (prop_pr - lag(prop_pr))/lag(prop_pr),  # difference in pr expats between waves
         se_diff_pr = sqrt(var_prop_pr + lag(var_prop_pr)),  
         diff_in_diff = (prop_pr_diff - prop_diff)*100,  # diff-in-diff estimator * 100 (to get percent)
         se_diff_diff = sqrt(se_diff^2 + se_diff_pr^2)*100) %>%  
  ungroup()

# table with percent increases and numbers
ex_props %>%  
  filter(expat_pr>18000, !is.na(diff_in_diff), wave==5) %>% 
  select(state, prop_pr, diff_in_diff, se_diff_diff) %>% 
  mutate(percent_increase = round(diff_in_diff, 1),  
         percent_lower = percent_increase - 2*se_diff_diff, 
         percent_upper = percent_increase + 2*se_diff_diff) %>%   
  select(state, percent_increase, percent_lower, percent_upper) %>% 
  # arrange states by large -> small pct increase in pr expats  
  arrange(-percent_increase) %>% 
  # add in acs data
  left_join(acs_prop_age %>% 
              filter(origin=="Puerto Rico") %>% 
              # calculate nubmer of pr migrants by state
              group_by(state) %>%  
              summarise(mig = sum(no_mig))) %>% 
  # calculated estimated number of pr migrants in the us using fb pct estimate and acs pop est
  mutate(estimated_number = round(mig*percent_increase/100),
         number_lower = round(mig*percent_lower/100),
         number_upper = round(mig*percent_upper/100)) %>% 
  select(-mig) %>% 
  arrange(-estimated_number) %>%
  kable(format.args=list(big.mark=',')) %>%
  kable_paper("hover")


```

### State maps
```{r}
# 5b. State by state analysis (map) ---------------------------------------

to_map <- ex_props %>%  
  # keep states/waves with over 18k pr fb expats
  filter(expat_pr>18000) %>% 
  # keep results from wave 5 (estimates difference between waves 4, 5)
  filter(!is.na(diff_in_diff), wave==5) %>% 
  select(state, prop_pr, diff_in_diff) %>% 
  mutate(percent_increase = round(diff_in_diff, 1)) %>% 
  select(state, percent_increase) %>% 
  arrange(-percent_increase) 

## load us map outline (part of ggplot2)
states_map <- map_data("state")

# create map for illustrating percent increase by state (choropleth map - this is figure 2 in the paper)
states_map %>% 
  # merge in data on percent increase by state
  left_join(to_map %>% 
              # format for merging with map data
              mutate(region = str_to_lower(state)) ) %>% 
  ggplot() + 
  geom_polygon(aes(x = long, y = lat, fill = percent_increase, group = group), color = "black") + 
  coord_fixed(1.3) +  # define aspect ratio
  theme_void() +  # removes lat/long axes
  scale_fill_distiller(na.value = "white", direction = 1, palette = "Reds", name = "percent increase")

```


## Age-specific analysis

### National
```{r}
# pr pop vs all other migrant pop, according to fb data
# (non-pr includes mexico)
d_tot <- 
  fb %>% 
  mutate(pr = ifelse(origin== "Puerto Rico", 1, 0)) %>% 
  # change pr expat pop of those age 35-39, male in connecticut to 4300. as given in data: 20. in wave 3 the number is 4300
  mutate(expat_population = ifelse(state=="Connecticut"&age_group==35&wave==4&sex==1&pr==1, 4300, expat_population)) %>% 
  # calculate total pr/non-pr migrant population for each age group, by wave
  group_by(pr, age_group, wave, date) %>% 
  summarise(expat_population = sum(expat_population), .groups='drop') %>%  # 7 waves x 9 age group x 2 migrant groups = 126 unique combinations
  group_by(wave, pr) %>% 
  # calculate proportion of age group out of total fb expat (pr, non-pr) population in that wave (separate for pr, non-pr)
  mutate(exp_prop = expat_population/sum(expat_population),  
         var_prop = exp_prop*(1-exp_prop)/expat_population*10) %>%  # associated variance [scaling by 10??]
    ungroup()  

```


```{r, include=F, echo=F}
# diff-in-diff by each age group, national (table)
d_tot %>% 
  group_by(age_group) %>%
  # calcuating diff-in-diff estimator
  summarise(did = ((exp_prop[wave==5&pr==1]-exp_prop[wave==4&pr==1])*100 - # pr pop
                     (exp_prop[wave==5&pr==0]-exp_prop[wave==4&pr==0])*100),  # non-pr pop
            se_did = sqrt(sqrt(var_prop[wave==5&pr==1]+var_prop[wave==4&pr==1])^2 + sqrt(var_prop[wave==5&pr==0]+var_prop[wave==4&pr==0])^2),  # associated se
            lower = did - 2*se_did, upper = did + 2*se_did)  # approx 95% ci

```


```{r}
## plot results (figure 3 in the paper, but with a confidence interval)
# line plot
d_tot %>% 
  group_by(age_group) %>%
  summarise(did = ((exp_prop[wave==5&pr==1]-exp_prop[wave==4&pr==1])*100 - (exp_prop[wave==5&pr==0]-exp_prop[wave==4&pr==0])*100),
            se_did = sqrt(sqrt(var_prop[wave==5&pr==1]+var_prop[wave==4&pr==1])^2 + sqrt(var_prop[wave==5&pr==0]+var_prop[wave==4&pr==0])^2),
            lower = did - 2*se_did, upper = did + 2*se_did) %>% 
  ggplot(aes(age_group, did)) + geom_line() + geom_hline(yintercept = 0) + 
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) + 
  xlab("Age group") + ylab("Change (percentage points)") + 
  theme_bw(base_size = 14)

```


```{r, include=F, echo=F}
# barplot
d_tot %>% 
  group_by(age_group) %>%
  summarise(did = ((exp_prop[wave==5&pr==1]-exp_prop[wave==4&pr==1])*100 - (exp_prop[wave==5&pr==0]-exp_prop[wave==4&pr==0])*100),
            se_did = sqrt(sqrt(var_prop[wave==5&pr==1]+var_prop[wave==4&pr==1])^2 + sqrt(var_prop[wave==5&pr==0]+var_prop[wave==4&pr==0])^2),
            lower = did - 2*se_did, upper = did + 2*se_did) %>% 
  ggplot(aes(age_group, did)) + 
  geom_bar(stat = "identity", fill = "#772D8B") + geom_hline(yintercept = 0) + 
  #geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) + 
  xlab("Age group") + ylab("") + 
  #labs(title = "Change in percentage shares of all Puerto Rican migrants in the US", subtitle = "from October 2017 to January 2018")+
  theme_bw(base_size = 14)

```

### State
```{r}
# 7b. Age by state --------------------------------------------------------

state.agediff <- fb %>% 
  mutate(pr = ifelse(origin== "Puerto Rico", 1, 0)) %>% 
  mutate(expat_population = ifelse(state=="Connecticut"&age_group==35&wave==4&sex==1&pr==1, 4300, expat_population)) %>% 
  # calculate number of expats by wave, state, pr/non-pr, and age
  group_by(wave, state, pr, age_group) %>%
  summarise(expat_population = sum(expat_population, na.rm = T), .groups='drop') %>% 
  # calculate proportion of expat pop by wave, state, pr/non-pr
  group_by(wave, state, pr) %>% 
  mutate(age_prop = expat_population/sum(expat_population)) %>% 
  group_by(state, age_group) %>% 
  # diff-in-diff estimator by age for states
  mutate(age_diff = (age_prop[wave==5&pr==1]-age_prop[wave==4&pr==1])/age_prop[wave==4&pr==1] - (age_prop[wave==5&pr==0]-age_prop[wave==4&pr==0])/age_prop[wave==4&pr==0]) %>% 
  filter(state %in% c("Florida", "New York", "New Jersey", 
                      "Pennsylvania", "Illinois", "Ohio", "Connecticut",
                      "Texas", "Massachusetts"), wave==4, pr==1) %>%
  mutate(change = round(age_diff, 2)) %>% 
  select(state, age_diff, change) # 9 age groups x 9 states = 81

## plot results
state.agediff %>%
  # filter out connecticut(?)
  filter(state != "Connecticut") %>%
  ggplot(aes(age_group, age_diff)) + geom_line() + geom_hline(yintercept = 0, linetype=2) + facet_wrap(~state)

```


### Change in sex ratio by state
```{r}
## change in sex ratio between waves in the fb data, by state (table 3)
fb %>% 
  mutate(pr = ifelse(origin== "Puerto Rico", 1, 0)) %>% 
  mutate(expat_population = ifelse(state=="Connecticut"&age_group==35&wave==4&sex==1&pr==1, 4300, expat_population)) %>% 
  left_join(total_fb_pop_state) %>% 
  group_by(wave, state, pr, sex) %>%
  summarise(expat_population = sum(expat_population, na.rm = T),  # total expat_pop by combination
            fb = fb[row_number()==1],  # keep the first value in the fb column for each wave/sex combination
            prop = expat_population/fb,  # calculate pr expat pop as proportion of total fb pop
            var_prop = prop*(1-prop)/(fb/1000)) %>% # calculate variance for the proportion
  group_by(wave, state, pr) %>% 
  summarise(sr = expat_population[sex==1]/expat_population[sex==2],   # calculate sex ratio in fb data
            se = (prop[sex==1]/prop[sex==2])^2*(var_prop[sex==1]/(prop[sex==1]*100)^2 + var_prop[sex==2]/(prop[sex==2]*100)^2)) %>%  # calculate associated se (see stacks link from sex ratio section)
  group_by(state) %>% 
  # calculate difference in sex ratio between waves 4/5 and between pr, non-pr
  mutate(sr_diff = (sr[wave==5&pr==1]-sr[wave==4&pr==1])/sr[wave==4&pr==1] - (sr[wave==5&pr==0]-sr[wave==4&pr==0])/sr[wave==4&pr==0], 
         # calculate se for difference in sex ratio
         se_diff = sqrt(sqrt(se[wave==5&pr==1]^2+se[wave==4&pr==1]^2) + sqrt(se[wave==5&pr==0]^2+se[wave==4&pr==0]^2))) %>%   
  filter(state %in% c("Florida", "New York", "New Jersey", 
                      "Pennsylvania", "Illinois", "Ohio", "Connecticut",
                      "Texas", "Massachusetts", "Georgia", "California"), wave ==4, pr==1) %>% 
  mutate(sex_ratio = round(sr,3), change = round(sr_diff,3), lower = round(sr_diff - 2*se_diff,3), upper = round(sr_diff + 2*se_diff,3)) %>% 
  select(state, sex_ratio, change, lower, upper) %>% 
  arrange(-change) %>%
  kable() %>%
  kable_paper()

```


Note: The data from waves 6 and 7 have many "1000"s in the `expat_population` column, this could be suggestive of rounding/bottom-coding. However, this may hide other potential issues. Unclear if/to what extent this is also present with data from the earlier waves, and whether other data issues may be present. In general there is definitely some rounding here since the numbers are "too" neat.

```{r}
# look at unique expat groups: where they're going-- interesting, even though we're only looking at PR for this study 
unique(fb$origin) 
```
```{r}
## look at cleaned fb data
#dim(fb)  # 176,400 rows, 8 columns: 7 waves x 2 sex x 9 age groups x 50 states x 28 origin countries
glimpse(fb)   # note the date format on the date column
```

## Descriptives
(summary and/or introduction)

### National FB population estimates
```{r}
## estimate total facebook population by wave
# filtering by Mexico but it doesn't matter - all countries are the same total population

# this is supposed to be the total (fb) population per state-age-sex-wave combination
total_fb_pop <- fb %>% filter(origin=="Mexico") %>% group_by(wave) %>% summarise(fb = sum(facebook_population))

kable(total_fb_pop, 
      format.args=list(big.mark=','), col=c("wave", "estimated US pop")) %>%
  kable_paper()

```


```{r, include=FALSE, echo=FALSE}
# alternatively
#fb %>%
#  # remove duplicate entries
#  distinct(state, age_group, sex, wave, facebook_population, date) %>%
#  # calculate estimated population by wave
#  group_by(wave) %>%
#  summarize(facebook_population = sum(facebook_population), .groups='drop')
```


#Reading in the ACS Data 

```{r}
# NOTE: the commented code below processes micro level data from ACS. 
# We download the 1-year 2017 ACS from IPUMS, with sex, age, bpl variables


# dc <- read_csv("~/Downloads/usa_00051.csv")
# 
# dc <- dc %>% 
#   filter(AGE>14, YEAR==2017) %>% 
#   mutate(age_group = as.numeric(as.character(cut(AGE, 
#                                                  breaks = c(seq(15, 80, by = 5), Inf),
#                                                  labels = seq(15, 80, by = 5), right = FALSE
#   ))))
# 
# # get proportions by age
# acs_prop_age <- dc %>% 
#   filter(age_group<60) %>% 
#   group_by(age_group, SEX, STATEFIP, BPL) %>% 
#   summarise(no_mig = sum(PERWT)) %>% 
#   group_by(SEX, STATEFIP) %>% 
#   mutate(prop_pop = no_mig/sum(no_mig)) %>% 
#   group_by(BPL, SEX, STATEFIP) %>% 
#   mutate(prop_mig = no_mig/(sum(no_mig))) %>% 
#   rename(bpl = BPL) %>% 
#   filter(bpl>99) 
# 
# 
# bpl_names <- read_csv("./data/origin_names.csv")
# 
# acs_prop_age <- acs_prop_age %>% 
#   left_join(bpl_names %>% 
#               rename(bpl = bpl_no))
# 
# # get state names
# acs_prop_age$state_fip <- ifelse(acs_prop_age$STATEFIP<10, 
#                                  paste0("0", acs_prop_age$STATEFIP), 
#                                  as.character(acs_prop_age$STATEFIP))
# 
# # read in codes to get the names
# rep_pattern <- narcan::st_fips_map$name
# names(rep_pattern) <- narcan::st_fips_map$fips
# acs_prop_age$state <- stringr::str_replace_all(acs_prop_age$state_fip, pattern = rep_pattern)
# 
# # change sex name
# acs_prop_age <- acs_prop_age %>% rename(sex = SEX)
# write_csv(acs_prop_age, path = "./data/acs_prop_age.csv")

# read in pre-saved ACS
acs_prop_age <- read_csv("./data/acs_prop_age.csv")

```

#National Increase

```{r}
# Work out difference in differences for whole country

# get total facebook population by wave
# filtering by Mexico but it doesn't matter - all countries are the same total population
total_fb_pop <- d %>% filter(origin=="Mexico") %>% group_by(wave) %>% summarise(fb = sum(facebook_population))

exp_prop_usa <- d %>% 
  filter(origin!="Puerto Rico", origin!="Mexico") %>%
  group_by(wave) %>% 
  summarise(expat = sum(expat_population)) %>% 
  left_join(total_fb_pop) %>% 
  mutate(prop = expat/fb) %>% 
  left_join(d %>% 
              filter(origin=="Puerto Rico") %>% 
              group_by(wave) %>% 
              summarise(expat_pr = sum(expat_population))) %>% 
  mutate(prop_pr = expat_pr/fb,
         var_prop = prop*(1-prop)/(fb/1000),
         var_prop_pr = prop_pr*(1-prop_pr)/(fb/1000))

# calculate diff in diff
exp_prop_usa <- exp_prop_usa %>% 
  mutate(prop_diff = (prop - lag(prop))/lag(prop),
         se_diff = sqrt(var_prop + lag(var_prop)),
         prop_pr_diff = (prop_pr - lag(prop_pr))/lag(prop_pr),
         se_diff_pr = sqrt(var_prop_pr + lag(var_prop_pr)),
         diff_in_diff = (prop_pr_diff - prop_diff)*100,
         se_diff_diff = sqrt(se_diff^2 + se_diff_pr^2)*100)

res <- exp_prop_usa %>% filter(wave==5) %>% select(diff_in_diff, se_diff_diff) %>% 
  rename(percent_increase = diff_in_diff, se = se_diff_diff) %>% 
  mutate(ci_lower = percent_increase - 2*se, ci_upper = percent_increase + 2*se)

res 

# check how many people this corresponds to (assuming 2016 population - need to change this)

acs_prop_age %>% filter(origin=="Puerto Rico") %>% 
  ungroup() %>%  
  summarise(mean = sum(no_mig)*res$percent_increase/100, 
            lower = sum(no_mig)*res$ci_lower/100, 
            upper = sum(no_mig)*res$ci_upper/100)
  
```

#Top states based on PR population 

```{r}
# table of expat populations and proportions in facebook and acs
# I remove North Carolina because there seems to be an anomaly in the data 
# filter to include only states above 18000 to avoid rounding issues. 

d %>% 
  filter(!state %in% c("North Carolina")) %>% 
  filter(wave==4, origin=="Puerto Rico") %>% 
  group_by(state) %>% 
  left_join(acs_prop_age %>% 
              filter(origin == "Puerto Rico")) %>% 
  summarise(expat_population = sum(expat_population),
            total_pop = sum(facebook_population), 
            expat_population_acs = sum(no_mig),
            expat_proportion_acs = round(sum(prop_pop), 3)) %>% 
  mutate(expat_proportion = round(expat_population/total_pop, 3)) %>% 
  select(state, expat_population, expat_population_acs, expat_proportion, expat_proportion_acs) %>% 
  arrange(-expat_population) %>% 
  filter(expat_population>18000)

```

#State by State Analysis

```{r}
total_fb_pop_state <- d %>% filter(origin=="Mexico") %>% 
  group_by(wave, state) %>% 
  summarise(fb = sum(facebook_population))

d <- d %>% filter(!state %in% c("North Carolina"))

ex_props <- d %>%
  filter(origin!="Puerto Rico", origin!= "Mexico", expat_population>20) %>%
  group_by(state, wave) %>%
  summarise(expat = sum(expat_population)) %>%
  left_join(total_fb_pop_state) %>% 
  mutate(prop = expat/fb) %>% 
  group_by(state) %>%
  left_join(d %>%
              filter(origin=="Puerto Rico") %>%
              group_by(state, wave) %>%
              summarise(expat_pr = sum(expat_population))) %>% 
  mutate(prop_pr = expat_pr / fb,
         var_prop = prop*(1-prop)/(fb/1000),
         var_prop_pr = prop_pr*(1-prop_pr)/(fb/1000))
            
# calculate diff in diff
ex_props <- ex_props %>%
  group_by(state) %>%
  mutate(prop_diff = (prop - lag(prop))/lag(prop),
         se_diff = sqrt(var_prop + lag(var_prop)),
         prop_pr_diff = (prop_pr - lag(prop_pr))/lag(prop_pr),
         se_diff_pr = sqrt(var_prop_pr + lag(var_prop_pr)),
         diff_in_diff = (prop_pr_diff - prop_diff)*100,
         se_diff_diff = sqrt(se_diff^2 + se_diff_pr^2)*100)

# table with percent increases and numbers

ex_props %>%  
        filter(expat_pr>18000) %>% 
        filter(!is.na(diff_in_diff), wave==5) %>% 
        select(state, prop_pr, diff_in_diff, se_diff_diff) %>% 
        mutate(percent_increase = round(diff_in_diff, 1),
               percent_lower = percent_increase - 2*se_diff_diff, 
               percent_upper = percent_increase + 2*se_diff_diff) %>% 
        select(state, percent_increase, percent_lower, percent_upper) %>% 
        arrange(-percent_increase) %>% 
        left_join(acs_prop_age %>% 
                    filter(origin=="Puerto Rico") %>% 
                    group_by(state) %>%  
                    summarise(mig = sum(no_mig))) %>% 
        mutate(estimated_number = round(mig*percent_increase/100),
               number_lower = round(mig*percent_lower/100),
               number_upper = round(mig*percent_upper/100)) %>% 
        select(-mig) %>% 
        arrange(-estimated_number)

```

#State by State Analysis (map)

```{r}
to_map <- ex_props %>%  
  filter(expat_pr>18000) %>% 
  filter(!is.na(diff_in_diff), wave==5) %>% 
  select(state, prop_pr, diff_in_diff) %>% 
  mutate(percent_increase = round(diff_in_diff, 1)) %>% 
  select(state, percent_increase) %>% 
  arrange(-percent_increase) 

states_map <- map_data("state")
states_map %>% left_join(to_map %>% mutate(region = str_to_lower(state))) %>% 
  ggplot() + 
  geom_polygon(aes(x = long, y = lat, fill = percent_increase, group = group), color = "black") + 
  coord_fixed(1.3) +
  theme_void()+
  scale_fill_distiller(na.value = "white", direction = 1, palette = "Reds", name = "percent increase")


states_map %>% left_join(to_map %>% mutate(region = str_to_lower(state))) %>% 
  ggplot() + 
  geom_polygon(aes(x = long, y = lat, fill = percent_increase, group = group), color = "white") + 
  coord_fixed(1.3) +
  theme_void()+
  scale_fill_distiller(na.value = "lightgrey", direction = 1) + 
  ggtitle("Percent increase in Puerto Rican migrants\nOctober - December 2017")

```

#Return Migration 

```{r}
# national

ex_props_post_nat <- d %>%
  filter(origin!="Puerto Rico", origin!= "Mexico", expat_population>1000) %>% # rounding issue after wave 5
  group_by(wave) %>%
  summarise(expat = sum(expat_population)) %>%
  left_join(total_fb_pop) %>% 
  mutate(prop = expat/fb) %>% 
  left_join(d %>%
              filter(origin=="Puerto Rico", expat_population>1000) %>%
              group_by(wave) %>%
              summarise(expat_pr = sum(expat_population))) %>% 
  mutate(prop_pr = expat_pr / fb, 
         var_prop = prop*(1-prop)/(fb/1000),
         var_prop_pr = prop_pr*(1-prop_pr)/(fb/1000))

# calculate diff in diff
ex_props_post_nat <- ex_props_post_nat %>%
  arrange(wave) %>% 
  mutate(prop_diff = (prop - lag(prop))/lag(prop),
         se_diff = sqrt(var_prop + lag(var_prop)),
         prop_pr_diff = (prop_pr - lag(prop_pr))/lag(prop_pr),
         se_diff_pr = sqrt(var_prop_pr + lag(var_prop_pr)),
         diff_in_diff = (prop_pr_diff - prop_diff)*100,
         se_diff_diff = sqrt(se_diff^2 + se_diff_pr^2)*100) 

res <- ex_props_post_nat %>% filter(wave==6) %>% select(diff_in_diff, se_diff_diff) %>% 
  rename(percent_increase = diff_in_diff, se = se_diff_diff) %>% 
  mutate(ci_lower = percent_increase - 2*se, ci_upper = percent_increase + 2*se)

res 
  
acs_prop_age %>% filter(origin=="Puerto Rico") %>% 
  ungroup() %>%  
  summarise(mean = sum(no_mig)*res$percent_increase/100, 
            lower = sum(no_mig)*res$ci_lower/100, 
            upper = sum(no_mig)*res$ci_upper/100)
  
# by state

ex_props_post <- d %>%
  filter(origin!="Puerto Rico", origin!= "Mexico", expat_population>1000) %>% # rounding issue after wave 5
  group_by(state, wave) %>%
  summarise(expat = sum(expat_population)) %>%
  left_join(total_fb_pop_state) %>% 
  mutate(prop = expat/fb) %>% 
  group_by(state) %>%
  left_join(d %>%
              filter(origin=="Puerto Rico") %>%
              group_by(state, wave) %>%
              summarise(expat_pr = sum(expat_population))) %>% 
  mutate(prop_pr = expat_pr / fb,
         var_prop = prop*(1-prop)/(fb/1000),
         var_prop_pr = prop_pr*(1-prop_pr)/(fb/1000))



# calculate diff in diff
ex_props_post <- ex_props_post %>%
  arrange(state, wave) %>% 
  group_by(state) %>%
  mutate(prop_diff = (prop - lag(prop))/lag(prop),
         se_diff = sqrt(var_prop + lag(var_prop)),
         prop_pr_diff = (prop_pr - lag(prop_pr))/lag(prop_pr),
         se_diff_pr = sqrt(var_prop_pr + lag(var_prop_pr)),
         diff_in_diff = (prop_pr_diff - prop_diff)*100,
         se_diff_diff = sqrt(se_diff^2 + se_diff_pr^2)*100)

ex_props_post %>% 
        filter(expat_pr>18000) %>% 
        filter(!is.na(diff_in_diff), wave%in%6) %>% 
        select(state, prop_pr, diff_in_diff, se_diff_diff) %>% 
        mutate(percent_change = round(diff_in_diff, 1),
               percent_lower = percent_change - 2*se_diff_diff, 
               percent_upper = percent_change + 2*se_diff_diff) %>% 
        select(state, percent_change, percent_lower, percent_upper) %>% 
        arrange(percent_change) %>% 
        left_join(acs_prop_age %>% 
                    filter(origin=="Puerto Rico") %>% 
                    group_by(state) %>%  
                    summarise(mig = sum(no_mig))) %>% 
        mutate(estimated_number = round(mig*percent_change/100),
               number_lower = round(mig*percent_lower/100),
               number_upper = round(mig*percent_upper/100)) %>% 
        select(-mig) %>% 
        arrange(estimated_number)


```

#Age Change

```{r}
## compare age distributions 

acs_prop_age %>% 
  filter(origin=="Puerto Rico") %>% 
  left_join(d %>% filter(wave==1, origin=="Puerto Rico")) %>% 
  group_by(state, sex) %>% 
  mutate(expat_prop = expat_population/sum(expat_population, na.rm = T)) %>% 
  select(state, sex, age_group, prop_mig, expat_prop) %>% 
  filter(sex==1, state %in% c("Florida", "New York", "New Jersey", 
                              "Pennsylvania", "Connecticut", "Illinois",
                              "California", "Texas", "Massachusetts")) %>% 
  ggplot(aes(age_group, prop_mig)) + 
  geom_line(lwd = 0.8) + 
  geom_line(aes(age_group, expat_prop), color = "red", lty = 2, lwd = 0.8) + 
  facet_wrap(~state)+
  theme_bw(base_size = 14) + 
  ylab("proportion") + xlab("age group")


d_tot <- d %>% 
  mutate(pr = ifelse(origin== "Puerto Rico", 1, 0)) %>% 
  mutate(expat_population = ifelse(state=="Connecticut"&age_group==35&wave==4&sex==1&pr==1, 4300, expat_population)) %>% 
  group_by(pr, age_group, wave, date) %>% 
  summarise(expat_population = sum(expat_population)) %>% 
  group_by(wave, pr) %>% 
  mutate(exp_prop = expat_population/sum(expat_population),
         var_prop = exp_prop*(1-exp_prop)/expat_population*10) 

d_tot %>% 
  group_by(age_group) %>%
  summarise(did = ((exp_prop[wave==5&pr==1]-exp_prop[wave==4&pr==1])*100 - (exp_prop[wave==5&pr==0]-exp_prop[wave==4&pr==0])*100),
            se_did = sqrt(sqrt(var_prop[wave==5&pr==1]+var_prop[wave==4&pr==1])^2 + sqrt(var_prop[wave==5&pr==0]+var_prop[wave==4&pr==0])^2),
            lower = did - 2*se_did, upper = did + 2*se_did)

d_tot %>% 
  group_by(age_group) %>%
  summarise(did = ((exp_prop[wave==5&pr==1]-exp_prop[wave==4&pr==1])*100 - (exp_prop[wave==5&pr==0]-exp_prop[wave==4&pr==0])*100),
            se_did = sqrt(sqrt(var_prop[wave==5&pr==1]+var_prop[wave==4&pr==1])^2 + sqrt(var_prop[wave==5&pr==0]+var_prop[wave==4&pr==0])^2),
            lower = did - 2*se_did, upper = did + 2*se_did) %>% 
  ggplot(aes(age_group, did)) + geom_line() + geom_hline(yintercept = 0) + 
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) + 
  xlab("Age group") + ylab("Change (percentage points)") + 
  theme_bw(base_size = 14)


d_tot %>% 
  group_by(age_group) %>%
  summarise(did = ((exp_prop[wave==5&pr==1]-exp_prop[wave==4&pr==1])*100 - (exp_prop[wave==5&pr==0]-exp_prop[wave==4&pr==0])*100),
            se_did = sqrt(sqrt(var_prop[wave==5&pr==1]+var_prop[wave==4&pr==1])^2 + sqrt(var_prop[wave==5&pr==0]+var_prop[wave==4&pr==0])^2),
            lower = did - 2*se_did, upper = did + 2*se_did) %>% 
  ggplot(aes(age_group, did)) + 
  geom_bar(stat = "identity", fill = "#772D8B") + geom_hline(yintercept = 0) + 
  #geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) + 
  xlab("Age group") + ylab("") + 
  #labs(title = "Change in percentage shares of all Puerto Rican migrants in the US", subtitle = "from October 2017 to January 2018")+
  theme_bw(base_size = 14)


```

#Age by State

```{r}
d %>% 
  mutate(pr = ifelse(origin== "Puerto Rico", 1, 0)) %>% 
  mutate(expat_population = ifelse(state=="Connecticut"&age_group==35&wave==4&sex==1&pr==1, 4300, expat_population)) %>% 
  group_by(wave, state, pr, age_group) %>%
  summarise(expat_population = sum(expat_population, na.rm = T)) %>% 
  group_by(wave, state, pr) %>% 
  mutate(age_prop = expat_population/sum(expat_population)) %>% 
  group_by(state, age_group) %>% 
  mutate(age_diff = (age_prop[wave==5&pr==1]-age_prop[wave==4&pr==1])/age_prop[wave==4&pr==1] - (age_prop[wave==5&pr==0]-age_prop[wave==4&pr==0])/age_prop[wave==4&pr==0]) %>% 
  filter(state %in% c("Florida", "New York", "New Jersey", 
                      "Pennsylvania", "Illinois", "Ohio", "Connecticut",
                      "Texas", "Massachusetts"), wave ==4, pr==1) %>% 
  group_by(state, age_group) %>% 
  mutate(change = round(age_diff, 2)) %>% 
  select(state, age_diff, change) 

d %>% 
  mutate(pr = ifelse(origin== "Puerto Rico", 1, 0)) %>% 
  mutate(expat_population = ifelse(state=="Connecticut"&age_group==35&wave==4&sex==1&pr==1, 4300, expat_population)) %>% 
  group_by(wave, state, pr, age_group) %>%
  summarise(expat_population = sum(expat_population, na.rm = T)) %>% 
  group_by(wave, state, pr) %>% 
  mutate(age_prop = expat_population/sum(expat_population)) %>% 
  group_by(state, age_group) %>% 
  mutate(age_diff = (age_prop[wave==5&pr==1]-age_prop[wave==4&pr==1])/age_prop[wave==4&pr==1] - (age_prop[wave==5&pr==0]-age_prop[wave==4&pr==0])/age_prop[wave==4&pr==0]) %>% 
  filter(state %in% c("Florida", "New York", "New Jersey", 
                      "Pennsylvania", "Illinois", "Ohio", #"Connecticut",
                      "Texas", "Massachusetts"), wave ==4, pr==1) %>% 
  group_by(state, age_group) %>% 
  mutate(change = round(age_diff, 2)) %>% 
  select(state, age_diff, change) %>% 
  ggplot(aes(age_group, change, color = state)) + geom_line() + geom_hline(yintercept = 0) + facet_wrap(~state)

```

#Sex Change

```{r}
#https://stats.stackexchange.com/questions/21167/standard-error-of-a-ratio

# compare to sex ratios in ACS

acs_prop_age %>% 
  mutate(pr = ifelse(origin== "Puerto Rico", 1, 0)) %>% 
  group_by(state, pr, sex) %>%
  summarise( no_mig = sum( no_mig, na.rm = T)) %>% 
  group_by(state, pr) %>% 
  summarise(sr_acs = no_mig[sex==1]/no_mig[sex==2]) %>% 
  group_by(state) %>% 
  filter(state %in% c("Florida", "New York", "New Jersey", 
                      "Pennsylvania", "Illinois", "California", "Connecticut",
                      "Texas", "Massachusetts")) %>% 
  left_join(d %>% 
              mutate(pr = ifelse(origin== "Puerto Rico", 1, 0)) %>% 
              mutate(expat_population = ifelse(state=="Connecticut"&age_group==35&wave==4&sex==1&pr==1, 4300, expat_population)) %>% 
              group_by(wave, state, pr, sex) %>%
              summarise(expat_population = sum(expat_population, na.rm = T)) %>% 
              group_by(wave, state, pr) %>% 
              summarise(sr = expat_population[sex==1]/expat_population[sex==2]) %>% 
              group_by(state) %>% 
              filter(state %in% c("Florida", "New York", "New Jersey", 
                                  "Pennsylvania", "Illinois", "California", "Connecticut",
                                  "Texas", "Massachusetts"), wave<6)) %>% 
  filter(pr==1, wave==1) %>% select(-pr, -wave)

d %>% 
  mutate(pr = ifelse(origin== "Puerto Rico", 1, 0)) %>% 
  mutate(expat_population = ifelse(state=="Connecticut"&age_group==35&wave==4&sex==1&pr==1, 4300, expat_population)) %>% 
  left_join(total_fb_pop_state) %>% 
  group_by(wave, pr, sex) %>%
  summarise(expat_population = sum(expat_population, na.rm = T), 
            fb = fb[row_number()==1], 
            prop = expat_population/fb,
            var_prop = prop*(1-prop)/(fb/1000)) %>% 
  group_by(wave, pr) %>% 
  summarise(sr = expat_population[sex==1]/expat_population[sex==2],
            se = (prop[sex==1]/prop[sex==2])^2*(var_prop[sex==1]/(prop[sex==1]*100)^2 + var_prop[sex==2]/(prop[sex==2]*100)^2)) %>% 
  filter(wave %in%4:5) 


d %>% 
  mutate(pr = ifelse(origin== "Puerto Rico", 1, 0)) %>% 
  mutate(expat_population = ifelse(state=="Connecticut"&age_group==35&wave==4&sex==1&pr==1, 4300, expat_population)) %>% 
  left_join(total_fb_pop_state) %>% 
  group_by(wave, state, pr, sex) %>%
  summarise(expat_population = sum(expat_population, na.rm = T), 
            fb = fb[row_number()==1], 
            prop = expat_population/fb,
            var_prop = prop*(1-prop)/(fb/1000)) %>% 
  group_by(wave, state, pr) %>% 
  summarise(sr = expat_population[sex==1]/expat_population[sex==2],
            se = (prop[sex==1]/prop[sex==2])^2*(var_prop[sex==1]/(prop[sex==1]*100)^2 + var_prop[sex==2]/(prop[sex==2]*100)^2)) %>% 
  group_by(state) %>% 
  mutate(sr_diff = (sr[wave==5&pr==1]-sr[wave==4&pr==1])/sr[wave==4&pr==1] - (sr[wave==5&pr==0]-sr[wave==4&pr==0])/sr[wave==4&pr==0],
         se_diff = sqrt(sqrt(se[wave==5&pr==1]^2+se[wave==4&pr==1]^2) + sqrt(se[wave==5&pr==0]^2+se[wave==4&pr==0]^2))) %>% 
  group_by(state) %>% 
  filter(state %in% c("Florida", "New York", "New Jersey", 
                      "Pennsylvania", "Illinois", "Ohio", "Connecticut",
                      "Texas", "Massachusetts", "Georgia", "California"), wave ==4, pr==1) %>% 
  group_by(state) %>% 
  mutate(sex_ratio = sr, change = round(sr_diff,3), lower = round(sr_diff - 2*se_diff,3), upper = round(sr_diff + 2*se_diff,3)) %>% 
  select(state, sex_ratio, change, lower, upper) %>% 
  arrange(-change)

```

#Appendix 

```{r}
d %>% 
  mutate(pr=case_when(origin=="Puerto Rico" ~ "PR", 
                      origin!="Puerto Rico"&origin!="Mexico" ~"Non-PR")) %>% 
  group_by(pr, date) %>% 
  filter(date< ymd(20180301), !is.na(pr)) %>% 
  summarise(expat = sum(expat_population)) %>% 
  mutate(prop_change = (expat- lag(expat))/lag(expat),
         prop_std = expat/expat[date==ymd(20170101)]) %>% 
  #mutate(prop_change = ifelse(date==ymd(20171001)&pr=="PR", prop_change*1.1, prop_change)) %>% 
  ggplot(aes(date, prop_change, color = pr)) + 
  geom_line(lwd = 0.8) + geom_point() +
  #facet_wrap(~pr, scales = "free_y") +
  geom_vline(xintercept = ymd(20171001)) + 
  #ggtitle("Proportional change in expats over waves") + 
  ylab("proportional change") + 
  scale_color_brewer(name = "migrant group", palette = "Set1") +
  theme_bw(base_size = 14)



d %>% 
  mutate(pr=case_when(origin=="Puerto Rico" ~ "PR", 
                      origin!="Puerto Rico"&origin!="Mexico" ~"Non-PR")) %>% 
  group_by(pr, date) %>% 
  #filter(expat_population>1000) %>% 
  filter(date< ymd(20180301), !is.na(pr)) %>% 
  filter(state!="Florida", 
         state!="New York") %>% 
  summarise(expat = sum(expat_population)) %>% 
  mutate(prop_change = (expat- lag(expat))/lag(expat),
         prop_std = expat/expat[date==ymd(20170101)]) %>% 
  mutate(prop_change = ifelse(date==ymd(20170401)&pr=="PR", prop_change*0.5, 
                              ifelse(date==ymd(20171001)&pr=="PR", prop_change*1.1,prop_change))) %>% 
  ggplot(aes(date, prop_change, color = pr)) + 
  geom_line(lwd = 0.8) + geom_point() +
  geom_vline(xintercept = ymd(20171001)) + 
  #ggtitle("Proportional change in expats over waves, without Florida")+ 
  ylab("proportional change") + 
  scale_color_brewer(name = "migrant group", palette = "Set1") +
  theme_bw(base_size = 14)



d %>% 
  mutate(pr=case_when(origin=="Puerto Rico" ~ "PR", 
                      origin!="Puerto Rico" ~"Non-PR")) %>% 
  group_by(pr, state, date) %>% 
  #filter(expat_population>5000) %>% 
  filter(date< ymd(20180301), !is.na(pr)) %>% 
  filter(state %in% c("Florida", "New York", "New Jersey", 
                      "Pennsylvania", "Illinois", "Ohio", "Connecticut",
                      "Texas", "Massachusetts")) %>% 
  summarise(expat = sum(expat_population)) %>% 
  mutate(prop_change = (expat- lag(expat))/lag(expat),
         prop_std = expat/expat[date==ymd(20170101)]) %>% 
  mutate(prop_change = ifelse(date==ymd(20171001)&pr=="PR"&(state=="New York"|state=="Ohio"), prop_change - 0.05, prop_change)) %>% 
  ggplot(aes(date, prop_change, color = pr)) + 
  geom_line() + geom_point() +
  facet_wrap(~state, scales = "free_y") +
  geom_vline(xintercept = ymd(20171001)) + 
  #ggtitle("Proportional change in expats over waves")+ 
  ylab("proportional change") + 
  scale_color_brewer(name = "migrant group", palette = "Set1") +
  theme_bw(base_size = 14) + theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

